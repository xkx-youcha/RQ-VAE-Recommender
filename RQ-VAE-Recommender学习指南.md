# RQ-VAE æ¨èç³»ç»Ÿå­¦ä¹ æŒ‡å—

## ğŸ“– é¡¹ç›®æ¦‚è¿°

RQ-VAE-Recommender æ˜¯ä¸€ä¸ªåŸºäºç”Ÿæˆå¼æ£€ç´¢çš„æ¨èç³»ç»Ÿå®ç°ï¼Œä½¿ç”¨è¯­ä¹‰IDï¼ˆSemantic IDsï¼‰å’Œæ®‹å·®é‡åŒ–å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆResidual Quantized Variational Autoencoder, RQ-VAEï¼‰ã€‚è¯¥é¡¹ç›®æ˜¯è®ºæ–‡ã€ŠRecommender Systems with Generative Retrievalã€‹çš„PyTorchå®ç°ã€‚

### ğŸ¯ æ ¸å¿ƒæ€æƒ³

ä¼ ç»Ÿçš„æ¨èç³»ç»Ÿé€šå¸¸ä½¿ç”¨åŒå¡”æ¨¡å‹ï¼ˆDual-Towerï¼‰æˆ–äº¤å‰ç¼–ç å™¨ï¼ˆCross-Encoderï¼‰è¿›è¡Œæ£€ç´¢å’Œæ’åºã€‚è€ŒRQ-VAEé‡‡ç”¨äº†ä¸€ç§å…¨æ–°çš„ç”Ÿæˆå¼æ£€ç´¢æ–¹æ³•ï¼š

1. **è¯­ä¹‰IDæ˜ å°„**ï¼šå°†ç‰©å“æ˜ å°„ä¸ºè¯­ä¹‰IDå…ƒç»„
2. **åºåˆ—ç”Ÿæˆ**ï¼šä½¿ç”¨Transformeræ¨¡å‹ç”Ÿæˆä¸‹ä¸€ä¸ªè¯­ä¹‰IDåºåˆ—

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹

```
ç¬¬ä¸€é˜¶æ®µï¼šRQ-VAE Tokenizerè®­ç»ƒ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç‰©å“ç‰¹å¾      â”‚ -> â”‚   RQ-VAEç¼–ç å™¨  â”‚ -> â”‚   è¯­ä¹‰IDå…ƒç»„    â”‚
â”‚   (768ç»´)       â”‚    â”‚   (3å±‚é‡åŒ–)     â”‚    â”‚   (3ä¸ªID)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç¬¬äºŒé˜¶æ®µï¼šæ£€ç´¢æ¨¡å‹è®­ç»ƒ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·åºåˆ—      â”‚ -> â”‚   Transformer   â”‚ -> â”‚   ä¸‹ä¸€ä¸ªè¯­ä¹‰ID  â”‚
â”‚   (è¯­ä¹‰IDåºåˆ—)  â”‚    â”‚   (è§£ç å™¨)      â”‚    â”‚   (é¢„æµ‹)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ ä»£ç ç»“æ„åˆ†æ

### æ ¸å¿ƒæ¨¡å—

#### 1. æ•°æ®å¤„ç†æ¨¡å— (`data/`)
- **`processed.py`**: æ•°æ®é›†å¤„ç†æ ¸å¿ƒ
  - `ItemData`: ç‰©å“æ•°æ®å¤„ç†
  - `SeqData`: åºåˆ—æ•°æ®å¤„ç†
  - æ”¯æŒAmazonã€MovieLens 1Mã€MovieLens 32Mæ•°æ®é›†

- **`amazon.py`**: Amazonè¯„è®ºæ•°æ®é›†
- **`ml1m.py`**: MovieLens 1Mæ•°æ®é›†  
- **`ml32m.py`**: MovieLens 32Mæ•°æ®é›†

#### 2. RQ-VAEæ¨¡å— (`modules/`)
- **`rqvae.py`**: RQ-VAEæ ¸å¿ƒå®ç°
  - å¤šå±‚æ®‹å·®é‡åŒ–
  - ç¼–ç å™¨-è§£ç å™¨æ¶æ„
  - è¯­ä¹‰IDç”Ÿæˆ

- **`quantize.py`**: é‡åŒ–æ¨¡å—
  - Gumbel-Softmaxé‡åŒ–
  - Rotation Trické‡åŒ–
  - K-meansåˆå§‹åŒ–

- **`encoder.py`**: MLPç¼–ç å™¨
- **`loss.py`**: æŸå¤±å‡½æ•°å®šä¹‰

#### 3. æ£€ç´¢æ¨¡å‹æ¨¡å— (`modules/`)
- **`model.py`**: ç¼–ç å™¨-è§£ç å™¨æ£€ç´¢æ¨¡å‹
  - Transformeræ¶æ„
  - è¯­ä¹‰IDåµŒå…¥
  - ç”¨æˆ·IDåµŒå…¥

- **`transformer/`**: Transformerå®ç°
  - `attention.py`: æ³¨æ„åŠ›æœºåˆ¶
  - `model.py`: Transformeræ¨¡å‹

- **`embedding/`**: åµŒå…¥å±‚
  - `id_embedder.py`: IDåµŒå…¥å™¨

#### 4. è®­ç»ƒè„šæœ¬
- **`train_rqvae.py`**: RQ-VAEè®­ç»ƒè„šæœ¬
- **`train_decoder.py`**: æ£€ç´¢æ¨¡å‹è®­ç»ƒè„šæœ¬

#### 5. é…ç½®æ–‡ä»¶ (`configs/`)
- **`rqvae_amazon.gin`**: Amazonæ•°æ®é›†RQ-VAEé…ç½®
- **`decoder_amazon.gin`**: Amazonæ•°æ®é›†è§£ç å™¨é…ç½®
- **`rqvae_ml32m.gin`**: MovieLens 32Mæ•°æ®é›†RQ-VAEé…ç½®
- **`decoder_ml32m.gin`**: MovieLens 32Mæ•°æ®é›†è§£ç å™¨é…ç½®

## ğŸ”„ è¯¦ç»†å·¥ä½œæµç¨‹

### ç¬¬ä¸€é˜¶æ®µï¼šRQ-VAEè®­ç»ƒ

#### 1. æ•°æ®å‡†å¤‡
```python
# ç‰©å“æ•°æ®å¤„ç†
train_dataset = ItemData(
    root=dataset_folder, 
    dataset=dataset, 
    force_process=force_dataset_process, 
    train_test_split="train" if do_eval else "all", 
    split=dataset_split
)
```

#### 2. æ¨¡å‹åˆå§‹åŒ–
```python
model = RqVae(
    input_dim=vae_input_dim,        # 768 (ç‰©å“ç‰¹å¾ç»´åº¦)
    embed_dim=vae_embed_dim,        # 32 (åµŒå…¥ç»´åº¦)
    hidden_dims=vae_hidden_dims,    # [512, 256, 128]
    codebook_size=vae_codebook_size, # 256 (ç æœ¬å¤§å°)
    n_layers=vae_n_layers,          # 3 (é‡åŒ–å±‚æ•°)
    commitment_weight=commitment_weight # 0.25
)
```

#### 3. è®­ç»ƒè¿‡ç¨‹
- **å‰å‘ä¼ æ’­**: ç‰©å“ç‰¹å¾ â†’ ç¼–ç å™¨ â†’ å¤šå±‚é‡åŒ– â†’ è¯­ä¹‰ID
- **æŸå¤±è®¡ç®—**: é‡æ„æŸå¤± + é‡åŒ–æŸå¤±
- **åå‘ä¼ æ’­**: æ›´æ–°ç¼–ç å™¨ã€è§£ç å™¨å’Œç æœ¬å‚æ•°

### ç¬¬äºŒé˜¶æ®µï¼šæ£€ç´¢æ¨¡å‹è®­ç»ƒ

#### 1. æ•°æ®å‡†å¤‡
```python
# åºåˆ—æ•°æ®å¤„ç†
train_dataset = SeqData(
    root=dataset_folder, 
    dataset=dataset, 
    is_train=True, 
    subsample=train_data_subsample, 
    split=dataset_split
)
```

#### 2. æ¨¡å‹åˆå§‹åŒ–
```python
model = EncoderDecoderRetrievalModel(
    embedding_dim=decoder_embed_dim,    # 128
    attn_dim=attn_embed_dim,           # 512
    dropout=dropout_p,                  # 0.3
    num_heads=attn_heads,              # 8
    n_layers=attn_layers,              # 8
    num_embeddings=vae_codebook_size,  # 256
    sem_id_dim=vae_n_layers            # 3
)
```

#### 3. è®­ç»ƒè¿‡ç¨‹
- **è¾“å…¥**: ç”¨æˆ·å†å²åºåˆ—ï¼ˆè¯­ä¹‰IDåºåˆ—ï¼‰
- **ç¼–ç **: åºåˆ—ç¼–ç  + ä½ç½®ç¼–ç 
- **è§£ç **: ç”Ÿæˆä¸‹ä¸€ä¸ªè¯­ä¹‰ID
- **æŸå¤±**: äº¤å‰ç†µæŸå¤±

## ğŸ›ï¸ å…³é”®é…ç½®å‚æ•°

### RQ-VAEé…ç½® (Amazon Beauty)
```gin
train.iterations=400000              # è®­ç»ƒè¿­ä»£æ¬¡æ•°
train.learning_rate=0.0005           # å­¦ä¹ ç‡
train.batch_size=64                  # æ‰¹æ¬¡å¤§å°
train.vae_input_dim=768              # è¾“å…¥ç»´åº¦
train.vae_embed_dim=32               # åµŒå…¥ç»´åº¦
train.vae_codebook_size=256          # ç æœ¬å¤§å°
train.vae_n_layers=3                 # é‡åŒ–å±‚æ•°
train.commitment_weight=0.25         # æ‰¿è¯ºæƒé‡
```

### æ£€ç´¢æ¨¡å‹é…ç½® (Amazon Beauty)
```gin
train.iterations=200000              # è®­ç»ƒè¿­ä»£æ¬¡æ•°
train.learning_rate=0.0003           # å­¦ä¹ ç‡
train.batch_size=256                 # æ‰¹æ¬¡å¤§å°
train.attn_heads=8                   # æ³¨æ„åŠ›å¤´æ•°
train.attn_embed_dim=512             # æ³¨æ„åŠ›ç»´åº¦
train.attn_layers=8                  # Transformerå±‚æ•°
train.decoder_embed_dim=128          # è§£ç å™¨åµŒå…¥ç»´åº¦
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. ç¯å¢ƒå‡†å¤‡
```bash
pip install -r requirements.txt
```

### 2. è®­ç»ƒRQ-VAE
```bash
# Amazon Beautyæ•°æ®é›†
python train_rqvae.py configs/rqvae_amazon.gin

# MovieLens 32Mæ•°æ®é›†
python train_rqvae.py configs/rqvae_ml32m.gin
```

### 3. è®­ç»ƒæ£€ç´¢æ¨¡å‹
```bash
# Amazon Beautyæ•°æ®é›†
python train_decoder.py configs/decoder_amazon.gin

# MovieLens 32Mæ•°æ®é›†
python train_decoder.py configs/decoder_ml32m.gin
```

## ğŸ” æ ¸å¿ƒç®—æ³•è¯¦è§£

### 1. æ®‹å·®é‡åŒ– (Residual Quantization)

RQ-VAEä½¿ç”¨å¤šå±‚é‡åŒ–æ¥ç”Ÿæˆè¯­ä¹‰IDï¼š

```python
# ç¬¬ä¸€å±‚é‡åŒ–
z1 = encoder(x)
q1, loss1 = quantize_layer1(z1)
residual1 = z1 - q1

# ç¬¬äºŒå±‚é‡åŒ–
z2 = encoder(residual1)
q2, loss2 = quantize_layer2(z2)
residual2 = z2 - q2

# ç¬¬ä¸‰å±‚é‡åŒ–
z3 = encoder(residual2)
q3, loss3 = quantize_layer3(z3)

# è¯­ä¹‰ID: [id1, id2, id3]
semantic_ids = [q1_idx, q2_idx, q3_idx]
```

### 2. Gumbel-Softmaxé‡åŒ–

åœ¨è®­ç»ƒæ—¶ä½¿ç”¨Gumbel-Softmaxè¿›è¡Œå¯å¾®åˆ†é‡åŒ–ï¼š

```python
def gumbel_softmax(logits, temperature=1.0):
    gumbels = -torch.empty_like(logits).exponential_().log()
    gumbels = (logits + gumbels) / temperature
    return F.softmax(gumbels, dim=-1)
```

### 3. åºåˆ—ç”Ÿæˆ

æ£€ç´¢æ¨¡å‹ä½¿ç”¨Transformerè§£ç å™¨ç”Ÿæˆä¸‹ä¸€ä¸ªè¯­ä¹‰IDï¼š

```python
def generate_next_sem_id(self, batch, temperature=1, top_k=True):
    # ç¼–ç ç”¨æˆ·åºåˆ—
    encoded = self.encode_sequence(batch)
    
    # ç”Ÿæˆä¸‹ä¸€ä¸ªID
    logits = self.transformer_decoder(encoded)
    
    # é‡‡æ ·ä¸‹ä¸€ä¸ªè¯­ä¹‰ID
    next_id = self.sample_next_id(logits, temperature, top_k)
    
    return next_id
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### 1. é‡æ„è´¨é‡
- **é‡æ„æŸå¤±**: è¡¡é‡RQ-VAEé‡æ„ç‰©å“ç‰¹å¾çš„èƒ½åŠ›
- **é‡åŒ–æŸå¤±**: è¡¡é‡ç æœ¬ä½¿ç”¨çš„æ•ˆç‡

### 2. æ¨èè´¨é‡
- **Top-Kå‡†ç¡®ç‡**: é¢„æµ‹çš„è¯­ä¹‰IDæ˜¯å¦åœ¨çœŸå®ç‰©å“çš„è¯­ä¹‰IDä¸­
- **å¬å›ç‡**: æ¨èç‰©å“çš„è¦†ç›–ç‡
- **å¤šæ ·æ€§**: æ¨èç»“æœçš„å¤šæ ·æ€§

## ğŸ¯ æŠ€æœ¯äº®ç‚¹

### 1. ç”Ÿæˆå¼æ£€ç´¢
- ä¸åŒäºä¼ ç»Ÿçš„æ£€ç´¢-æ’åºèŒƒå¼
- ç›´æ¥ç”Ÿæˆä¸‹ä¸€ä¸ªç‰©å“çš„è¯­ä¹‰ID
- æ”¯æŒåºåˆ—æ¨èå’Œä¼šè¯æ¨è

### 2. è¯­ä¹‰IDè¡¨ç¤º
- å°†ç‰©å“æ˜ å°„ä¸ºç¦»æ•£çš„è¯­ä¹‰ID
- ä¿æŒç‰©å“çš„è¯­ä¹‰ç›¸ä¼¼æ€§
- æ”¯æŒé«˜æ•ˆçš„ç´¢å¼•å’Œæ£€ç´¢

### 3. æ®‹å·®é‡åŒ–
- å¤šå±‚é‡åŒ–æé«˜è¡¨è¾¾èƒ½åŠ›
- æ¸è¿›å¼ç‰¹å¾æå–
- å¹³è¡¡å‹ç¼©ç‡å’Œé‡æ„è´¨é‡

### 4. å¯æ‰©å±•æ€§
- æ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†
- æ¨¡å—åŒ–è®¾è®¡
- æ˜“äºæ‰©å±•å’Œä¿®æ”¹

## ğŸ”— ç›¸å…³è®ºæ–‡

1. **Recommender Systems with Generative Retrieval** - ä¸»è¦è®ºæ–‡
2. **Categorical Reparametrization with Gumbel-Softmax** - Gumbel-SoftmaxæŠ€æœ¯
3. **Restructuring Vector Quantization with the Rotation Trick** - Rotation TrickæŠ€æœ¯

## ğŸ’¡ å­¦ä¹ å»ºè®®

### 1. ç†è®ºåŸºç¡€
- ç†è§£å˜åˆ†è‡ªç¼–ç å™¨(VAE)åŸç†
- å­¦ä¹ æ®‹å·®é‡åŒ–æŠ€æœ¯
- æŒæ¡Transformeræ¶æ„

### 2. ä»£ç å®è·µ
- ä»é…ç½®æ–‡ä»¶å¼€å§‹ç†è§£å‚æ•°è®¾ç½®
- é€æ­¥è°ƒè¯•è®­ç»ƒæµç¨‹
- åˆ†ææ¨¡å‹è¾“å‡ºå’Œä¸­é—´ç»“æœ

### 3. å®éªŒæ¢ç´¢
- å°è¯•ä¸åŒçš„æ•°æ®é›†
- è°ƒæ•´æ¨¡å‹å‚æ•°
- æ¯”è¾ƒä¸åŒé‡åŒ–ç­–ç•¥çš„æ•ˆæœ

### 4. æ‰©å±•åº”ç”¨
- åº”ç”¨åˆ°å…¶ä»–æ¨èåœºæ™¯
- é›†æˆåˆ°ç°æœ‰æ¨èç³»ç»Ÿ
- ä¼˜åŒ–æ¨ç†æ€§èƒ½

---

*è¿™ä»½å­¦ä¹ æŒ‡å—æ¶µç›–äº†RQ-VAEæ¨èç³»ç»Ÿçš„æ ¸å¿ƒæ¦‚å¿µã€æ¶æ„è®¾è®¡ã€å®ç°ç»†èŠ‚å’Œä½¿ç”¨æ–¹æ³•ï¼Œå¸Œæœ›èƒ½å¸®åŠ©ä½ æ·±å…¥ç†è§£è¿™ä¸ªåˆ›æ–°çš„æ¨èç³»ç»Ÿæ–¹æ³•ã€‚* 